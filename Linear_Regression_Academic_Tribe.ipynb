{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sijuswamy/Algorithmic-Thinking-FDP/blob/main/Linear_Regression_Academic_Tribe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8QNcPduPuY6"
      },
      "source": [
        "\n",
        "# Linear Regression Models in Machine Learning (Academic Tribe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZxaU29XPuZC"
      },
      "source": [
        "## Introduction\n",
        "Linear Regression is a machine learning algorithm based on supervised learning. It performs a regression task. Regression models a target prediction value based on independent variables. It is mostly used for finding out the relationship between variables and forecasting. Different regression models differ based on – the kind of relationship between dependent and independent variables, they are considering and the number of independent variables being used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAij5PGePuZE"
      },
      "source": [
        "## Linear Regression Job\n",
        "\n",
        "Linear regression performs the task to predict a dependent variable value ($y$) based on a given independent variable ($x$). So, this regression technique finds out a linear relationship between $x$ (input) and $y$(response). Hence, the name is Linear Regression.\n",
        " For example $X$ (input) is the work experience and $Y$ (output) is the salary of a person. The regression line is the best fit line for our SLR model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5T2N7ONPuZF"
      },
      "source": [
        "## Hypothesis of SLRM\n",
        "\n",
        "The proposed model is $$h_\\theta(x)=\\theta_0+\\theta_1 x$$, where $\\theta_0$ is the intercept of the line and $\\theta_1$ is the slope. In case of multiple linear regression the vector form of LR is $$h_\\theta=\\theta^TX+\\theta_0$$\n",
        "\n",
        "where $\\theta=(\\theta_1,\\theta_2\\ldots,\\theta_n)^T$\n",
        "\n",
        "The hypothesis are:\n",
        "\n",
        "> $H_0$: $\\theta_1=0$\n",
        "\n",
        "> $H_1$: $\\theta_1\\neq 0$\n",
        "\n",
        "While training the model we are given :\n",
        "\n",
        ">1.$x$: input training data (univariate – one input variable(parameter))\n",
        "\n",
        ">2.$y$: labels to data (supervised learning)\n",
        "\n",
        ">3.When training the model – it fits the best line to predict the value of y for a given value of x. The model gets the best regression fit line by finding the best $\\theta_0$ and $\\theta_1$ values.\n",
        "$\\theta_0$: intercept\n",
        "$\\theta_1$: coefficient of x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21EUnfvUPuZH"
      },
      "source": [
        "## Moving in SLR model building\n",
        "Once we find the best $\\theta_0$ and $\\theta_1$ values, we get the best fit line. So when we are finally using our model for prediction, it will predict the value of $y$ for the input value of $x$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9K2Gz29PuZI"
      },
      "source": [
        "## 1. Least square error method\n",
        "\n",
        "In this method, we simply calculate the parameters $\\theta_0$ and $\\theta_1$ can be calculated using the following algebraic expressions:\n",
        "\n",
        "\\begin{align*}\n",
        "\\theta_1&=\\dfrac{\\sum\\limits_{i=1}^m\\left(x_i-\\bar{x}\\right)\\left(y_i-\\bar{y}\\right)}{\\sum\\limits_{i=1}^m\\left(x_i-\\bar{x}\\right)^2}\\\\\n",
        "\\theta_0&=\\bar{y}-\\theta_1\\bar{x}\n",
        "\\end{align*}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VFX1DgM8PuZJ",
        "outputId": "533d7a0c-94a3-4eb8-e7c3-791bd963f32c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "slope : 4.0\n",
            "Intercept : 6.753999999999998\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "x=np.array([1,2,3,4,5,6,7,8])\n",
        "y=4*x+6.754\n",
        "nr=np.sum((np.multiply(y-np.mean(y),x-np.mean(x))))\n",
        "dnr=np.sum((x-np.mean(x))**2)\n",
        "# print(nr)\n",
        "# print(dnr)\n",
        "theta_1=nr/dnr\n",
        "theta_0=np.mean(y)-theta_1*np.mean(x)\n",
        "print(\"slope :\",theta_1)\n",
        "print(\"Intercept :\",theta_0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr2SLq9gPuZO"
      },
      "source": [
        "## Direct method in statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vgZVY-fvPuZP",
        "outputId": "6dcb59c7-bccd-43b7-e06e-502a0ad391c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/stats/_stats_py.py:1806: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=8\n",
            "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                                 OLS Regression Results                                \n",
              "=======================================================================================\n",
              "Dep. Variable:                      y   R-squared (uncentered):                   0.987\n",
              "Model:                            OLS   Adj. R-squared (uncentered):              0.985\n",
              "Method:                 Least Squares   F-statistic:                              512.3\n",
              "Date:                Wed, 24 Jul 2024   Prob (F-statistic):                    8.32e-08\n",
              "Time:                        08:30:50   Log-Likelihood:                         -20.311\n",
              "No. Observations:                   8   AIC:                                      42.62\n",
              "Df Residuals:                       7   BIC:                                      42.70\n",
              "Df Model:                           1                                                  \n",
              "Covariance Type:            nonrobust                                                  \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "x1             5.1919      0.229     22.635      0.000       4.649       5.734\n",
              "==============================================================================\n",
              "Omnibus:                        0.679   Durbin-Watson:                   0.132\n",
              "Prob(Omnibus):                  0.712   Jarque-Bera (JB):                0.511\n",
              "Skew:                           0.000   Prob(JB):                        0.775\n",
              "Kurtosis:                       1.762   Cond. No.                         1.00\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
              "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.987</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.985</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   512.3</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Wed, 24 Jul 2024</td> <th>  Prob (F-statistic):</th>          <td>8.32e-08</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>08:30:50</td>     <th>  Log-Likelihood:    </th>          <td> -20.311</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>     8</td>      <th>  AIC:               </th>          <td>   42.62</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>     7</td>      <th>  BIC:               </th>          <td>   42.70</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th> <td>    5.1919</td> <td>    0.229</td> <td>   22.635</td> <td> 0.000</td> <td>    4.649</td> <td>    5.734</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 0.679</td> <th>  Durbin-Watson:     </th> <td>   0.132</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.712</td> <th>  Jarque-Bera (JB):  </th> <td>   0.511</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.000</td> <th>  Prob(JB):          </th> <td>   0.775</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 1.762</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared (uncentered):}      &     0.987   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.985   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       }          &     512.3   \\\\\n\\textbf{Date:}             & Wed, 24 Jul 2024 & \\textbf{  Prob (F-statistic):}          &  8.32e-08   \\\\\n\\textbf{Time:}             &     08:30:50     & \\textbf{  Log-Likelihood:    }          &   -20.311   \\\\\n\\textbf{No. Observations:} &           8      & \\textbf{  AIC:               }          &     42.62   \\\\\n\\textbf{Df Residuals:}     &           7      & \\textbf{  BIC:               }          &     42.70   \\\\\n\\textbf{Df Model:}         &           1      & \\textbf{                     }          &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     }          &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{x1} &       5.1919  &        0.229     &    22.635  &         0.000        &        4.649    &        5.734     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       &  0.679 & \\textbf{  Durbin-Watson:     } &    0.132  \\\\\n\\textbf{Prob(Omnibus):} &  0.712 & \\textbf{  Jarque-Bera (JB):  } &    0.511  \\\\\n\\textbf{Skew:}          &  0.000 & \\textbf{  Prob(JB):          } &    0.775  \\\\\n\\textbf{Kurtosis:}      &  1.762 & \\textbf{  Cond. No.          } &     1.00  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n [2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import statsmodels.api as sm\n",
        "# Note the difference in argument order\n",
        "model = sm.OLS(y, x).fit()\n",
        "predictions = model.predict(x) # make the predictions by the model\n",
        "\n",
        "# Print out the statistics\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3gz0WM0PuZR"
      },
      "source": [
        "Ordinary Least Square method looks simple and computation is easy. But, this OLS method will only work for a univariate dataset which is single dependent variable and single independent variable. Multi-variate dataset contains a single dependent variable and multiple independent variable sets, forced us to use a machine learning algorithm called “Gradient Descent”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeS09bTfPuZU"
      },
      "source": [
        "## Optimizing Regression line- Gradient descent method\n",
        "\n",
        "**Updating $\\theta_0$ and $\\theta_1$ values to get the best fit line**.\n",
        "\n",
        " While learning linear regression ML course, two functions are introduced:\n",
        "\n",
        "1. the cost function\n",
        "2. gradient descent\n",
        "\n",
        "**What is a Cost Function?**\n",
        "\n",
        "In the case of gradient descent, the objective is to find a line of best fit for some given inputs, or X values, and any number of Y values, or outputs. A cost function is defined as:\n",
        "\n",
        ">…a function that maps an event or values of one or more variables onto a real number intuitively representing some “cost” associated with the event.\n",
        "from Wikipedia\n",
        "\n",
        "In this situation, the event we are finding the cost of is the difference between estimated values, or the hypothesis and the real values — the actual data we are trying to fit a line to.\n",
        "\n",
        "By achieving the best-fit regression line, the model aims to predict y value such that the error difference between predicted value and true value is minimum. So, it is very important to update the $\\theta_0$ and $\\theta_1$ values, to reach the best value that minimize the error between predicted y value (pred) and true y value (y).\n",
        "\n",
        "The cost function in the case of SLR is the $MSE$ in prediction. Formally it can be defined as:\n",
        "\n",
        "$$ J(\\theta_0,\\theta_1)=\\frac{1}{2m}\\sum\\limits_{i=1}^m\\left(h_\\theta(x^i)-\\hat{y}^i\\right)^2$$\n",
        "\n",
        "Using Gradient descent algorithm , we will figure out a minimal cost function by applying various parameters for $\\theta_0$ and $\\theta_1$ and see the slope intercept until it reaches convergence.\n",
        "\n",
        ">In a real world example, it is similar to find out a best direction to take a step downhill.\n",
        "\n",
        "We take a step towards the direction to get down. From the each step, you look out the direction again to get down faster and downhill quickly. The similar approach is using in this algorithm to minimise cost function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePUVsYDsPuZW"
      },
      "source": [
        "## Gradient Descent for Linear Regression\n",
        "\n",
        "The gradient descent for the SLR cost function can be found using Classical calculus method. Since the cost function contains the parameters $\\theta_0$ and $\\theta_1$, the partial derivative curresponding to these parameters together defines the gradient. Mathematically\n",
        "\n",
        "\\begin{align*}\n",
        "\\dfrac{\\partial}{\\partial \\theta_0}\\left(J(\\theta_0,\\theta_1)\\right)&=\\dfrac{\\partial}{\\partial \\theta_0}\\left(\\frac{1}{2m}\\sum\\limits_{i=1}^m\\left(h_\\theta(x^i)-\\hat{y}^i\\right)^2\\right)\\\\\n",
        "\\dfrac{\\partial}{\\partial \\theta_1}\\left(J(\\theta_0,\\theta_1)\\right)&=\\dfrac{\\partial}{\\partial \\theta_1}\\left(\\frac{1}{2m}\\sum\\limits_{i=1}^m\\left(h_\\theta(x^i)-\\hat{y}^i\\right)^2\\right)\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xijmmosPuZW"
      },
      "source": [
        ">Why do we use partial derivative in the equation? Partial derivatives represents the rate of change of the functions as the variable change. In our case we change values for theta 0 and theta 1 and identifies the rate of change."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udHMk0zNPuZX"
      },
      "source": [
        "To apply rate of change values for theta 0 and theta 1, the below are the equations for theta 0 and theta 1 to apply it on each epoch.\n",
        "\n",
        "\\begin{align*}\n",
        "\\theta_0'&=\\frac{1}{m}\\sum\\limits_{i=1}^m\\left(h_\\theta(x^i)-\\hat{y}^i\\right)\\\\\n",
        "\\theta_1'&=\\frac{1}{m}\\sum\\limits_{i=1}^m\\left(h_\\theta(x^i)-\\hat{y}^i\\right)x^i\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrBAo2nOPuZY"
      },
      "source": [
        "To find the best minimum cost, repeat steps to apply various values for $\\theta_0$ and $\\theta_1$. In other words, repeat steps until convergence evaluate the following:\n",
        "\n",
        "\\begin{align*}\n",
        "\\theta_0^{(i+1)}&=\\theta_0^i-\\eta\\theta_0'^{(i)}\\\\\n",
        "\\theta_1^{(i+1)}&=\\theta_1^i-\\eta\\theta_1'^{(i)}\\\\\n",
        "\\end{align*}\n",
        "\n",
        "where $\\eta$ is the learning rate.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9smjAjXYPuZY"
      },
      "source": [
        "## Multiple Linear regression\n",
        "In the case of multiple linear regression, we have an input vector $X$ and the ground truth is $\\hat{y}$. The cost function in the case of MLR is the $MSE$ in prediction. Formally it can be defined as:\n",
        "\n",
        "$$ J(\\theta)=\\frac{1}{2m}\\sum\\limits_{i=1}^m\\left(h_\\theta(X^i)-\\hat{y}^i\\right)^2$$. Now the minimum direction is found by calculating gradient. Here we will have more partial derivatives like:\n",
        "\\begin{align*}\n",
        "\\theta_0'&=\\frac{1}{m}\\sum\\limits_{i=1}^m\\left(h_\\theta(X^i)-\\hat{y}^i\\right)\\\\\n",
        "\\theta_1'&=\\frac{1}{m}\\sum\\limits_{i=1}^m\\left(h_\\theta(X^i)-\\hat{y}^i\\right)x_1^i\\\\\n",
        "\\theta_2'&=\\frac{1}{m}\\sum\\limits_{i=1}^m\\left(h_\\theta(X^i)-\\hat{y}^i\\right)x_2^i\\\\\n",
        "\\cdots&\\cdots\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLxK6vJ6PuZZ"
      },
      "source": [
        "Now the updates in $\\theta$ will be summarized as:\n",
        "    \\begin{align*}\n",
        "\\theta_0^{(i+1)}&=\\theta_0^i-\\eta\\theta_0'^{(i)}\\\\\n",
        "\\theta_1^{(i+1)}&=\\theta_1^i-\\eta\\theta_1'^{(i)}\\\\\n",
        "\\theta_2^{(i+1)}&=\\theta_2^i-\\eta\\theta_2'^{(i)}\\\\\n",
        "\\cdots&\\cdots\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr1vCfLUPuZZ"
      },
      "source": [
        "# Example: Gradient descent in Python from scratch\n",
        "## Case 1: Simple Linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z9lljS9RPuZa",
        "outputId": "3d48f7f3-a244-4aa4-c69a-112edb5a064b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4.51454832]\n",
            " [2.99817352]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt# ensure to use matplot library for plotting\n",
        "np.random.seed(43)# ensure reproducible research\n",
        "X=2*np.random.rand(100,1)# a column of 100 random numbers\n",
        "y=4+3*X+np.random.rand(100,1)\n",
        "X_b=np.concatenate([np.ones((100,1)), X], axis=1)# reformulate X\n",
        "eta=0.1 # define learning rate\n",
        "n_iter=1000 # number of epochs\n",
        "m=100 # number of samples\n",
        "theta=np.random.rand(2,1) # create an initial setup for theta\n",
        "for ind in range(n_iter):\n",
        "    grad=1/m*X_b.T.dot(X_b.dot(theta)-y)\n",
        "    theta=theta-eta*grad\n",
        "print(theta)\n",
        "y_p=X_b.dot(theta)\n",
        "#print(y_p.T) # predicted values\n",
        "#print(y) # actual values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ac2SxZhPuZb"
      },
      "source": [
        "## Case 2: Multiple linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QmmAsXg6PuZb",
        "outputId": "b106064d-2f2f-4fa4-98fa-0be7e0495680",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4.55222768]\n",
            " [2.00029634]\n",
            " [0.96414812]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt# ensure to use matplot library for plotting\n",
        "np.random.seed(42)# ensure reproducible research\n",
        "X=2*np.random.rand(100,2)# two columns of 100 random numbers\n",
        "t=np.array([2,1])\n",
        "y=4+np.dot(X,t.T).reshape(100,1)+np.random.rand(100,1)\n",
        "X_b=np.concatenate([np.ones((100,1)), X], axis=1)# reformulate X\n",
        "eta=0.1 # define learning rate\n",
        "n_iter=1000 # number of epochs\n",
        "m=100 # number of samples\n",
        "theta=np.random.rand(3,1) # create an initial setup for theta\n",
        "for ind in range(n_iter):\n",
        "    grad=1/m*X_b.T.dot(X_b.dot(theta)-y)\n",
        "    theta=theta-eta*grad\n",
        "print(theta)\n",
        "y_p=X_b.dot(theta)\n",
        "#print(y_p.T) # predicted values\n",
        "#print(y) # actual values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t59otiRwPuZc"
      },
      "source": [
        "# 2. Using Scikit-learn machine learning libray in Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taTgactXPuZc"
      },
      "source": [
        "We know that linear regression is a popular technique and we might as well seen the mathematical equation of linear regression.  There are several ways in which we can do that, we can do linear regression using numpy, scipy, stats model and sckit learn. But in this post I am going to use scikit learn to perform linear regression.\n",
        "\n",
        "Scikit-learn is a powerful Python module for machine learning. It contains function for regression, classification, clustering, model selection and dimensionality reduction. Today, I will explore the sklearn.linear_model module which contains “methods intended for regression in which the target value is expected to be a linear combination of the input variables”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dcOqfaAPuZd"
      },
      "source": [
        "**Important points**: Important functions to keep in mind while fitting a linear regression model are:\n",
        "\n",
        ">1. `lm.fit()` -> fits a linear model\n",
        "\n",
        ">2. `lm.predict()` -> Predict Y using the linear model with estimated coefficients\n",
        "\n",
        ">3. `lm.score()` -> Returns the coefficient of determination ($R^2$). A measure of how well observed outcomes are replicated by the model, as the proportion of total variation of outcomes explained by the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU4AZArGPuZe"
      },
      "source": [
        "# A direct regression problem with sklearn library- Piza price model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXevk_DCPuZe"
      },
      "source": [
        "## 1. reading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HANAsk78PuZe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "X=[6,8,10,14,18]# reading as a list\n",
        "Y=[7,9,13,17.5,18]\n",
        "X=np.array(X).reshape(5,1) # converting list to a numpy array\n",
        "Y=np.array(Y).reshape(5,1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaNZjCV-kOLt",
        "outputId": "d3c07862-7bdb-4b7e-b3ae-c17abb128080"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7. ],\n",
              "       [ 9. ],\n",
              "       [13. ],\n",
              "       [17.5],\n",
              "       [18. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G850_TdPuZf"
      },
      "source": [
        "## 2.a Visualizing as a scatter plot using Matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xDPkw3jFPuZf",
        "outputId": "cfc90d60-6bb3-4c21-95c2-610b517c2bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-98d8183f438c>:2: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
            "  plt.style.use('seaborn-whitegrid')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt# ensure to use matplot library for plotting\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "plt.xlabel(\" Size of piza\")\n",
        "plt.ylabel(\" Price of piza\")\n",
        "plt.scatter(X,Y)\n",
        "plt.plot(X,Y,'r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha9FPPfgPuZg"
      },
      "source": [
        "## 2.b Finding linear regression model parameters statistically\n",
        "\n",
        "$var(x)=\\frac{\\sum_{i=1}^n(x-\\bar{x})^2}{n-1}$\n",
        "\n",
        "$\\theta_1=\\frac{\n",
        "cov(x,y)}{var(x)}$;\n",
        "\n",
        "$\\theta_0=\\bar{y}-\\theta_1*\\bar{x}$\n",
        "\n",
        "$R^2=1-\\frac{SS_{res}}{SS_{tot}}$\n",
        "\n",
        "$SS_{res}=\\sum_{i=1}^n(y_i-f(x_i))^2$\n",
        "\n",
        "$SS_{tot}=\\sum_{i=1}^n(y_i-\\bar{y})^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Uv8F3qPVPuZh",
        "outputId": "98c26d04-770c-435b-8801-1a77ff1c8f0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23.2\n",
            "22.650000000000002\n",
            "Intercept: 1.9655172413793096\n",
            "Slope:  0.976293103448276\n"
          ]
        }
      ],
      "source": [
        "xL=[i[0] for i in X]\n",
        "yL=[i[0] for i in Y]\n",
        "var_x=np.var(xL,ddof=1)# d degrees of freedom\n",
        "cov_xy=np.cov(xL,yL,ddof=1)[0][1]\n",
        "print(var_x)\n",
        "print(cov_xy)\n",
        "xbar=np.mean(xL)\n",
        "ybar=np.mean(yL)\n",
        "theta_1=cov_xy/var_x\n",
        "theta_0=ybar-(theta_1*xbar)\n",
        "print(\"Intercept:\",theta_0)\n",
        "y_p=theta_0+theta_1*X\n",
        "print(\"Slope: \", theta_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The regression equation is: $y=1.965+0.9762 x$"
      ],
      "metadata": {
        "id": "TBQu98edlyYZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE6h7v0SPuZi"
      },
      "source": [
        "## 3. Creating the model and finding parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9JHjgl2qPuZi"
      },
      "outputs": [],
      "source": [
        "#loading the machine learning library\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# creating an instance of the Linear Regression\n",
        "model=LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "model.fit(X,Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "HyOrKzzmnmAb",
        "outputId": "82caa0d3-32e8-4bb6-df9c-74406fa10cea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('estimated Intercept:',model.intercept_)\n",
        "print('number of coefficients',len(model.coef_))\n",
        "print(' coefficients',model.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHDdKB6PoAu-",
        "outputId": "291423c0-72dd-4f7a-deac-5991cb9b1db1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "estimated Intercept: [1.96551724]\n",
            "number of coefficients 1\n",
            " coefficients [[0.9762931]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the model"
      ],
      "metadata": {
        "id": "ONTkDdHg3lwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# save model with joblib\n",
        "filename = 'joblib_model.sav'\n",
        "joblib.dump(model, filename)"
      ],
      "metadata": {
        "id": "nGJAOlmJ2jhi",
        "outputId": "b1dc779b-bfbd-49b8-a4d9-c8c9fed3aa9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['joblib_model.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1aIa1dRR2qNW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8APJGZWRPuZi"
      },
      "source": [
        "## 4. Predict using scikit learn library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HZ2xP3SYPuZj",
        "outputId": "ae900435-6d2b-4d55-c180-e031182fa0bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.22413793]\n",
            " [-2.25215517]\n",
            " [ 2.29525862]\n",
            " [ 0.4137931 ]\n",
            " [-2.68103448]]\n"
          ]
        }
      ],
      "source": [
        "# new data for testing\n",
        "x_test=np.array([8,9,11,16,12]).reshape(5,1)\n",
        "y_test=np.array([11,8.5,15,18,11]).reshape(5,1)\n",
        "# predict the model ouput on the new data\n",
        "yp_test=model.predict(x_test)\n",
        "print(y_test-yp_test)\n",
        "#print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model with joblib\n",
        "loaded_model = joblib.load(filename)\n",
        "\n",
        "# evaluate model\n",
        "y_predict = loaded_model.predict(x_test)\n",
        "\n",
        "# check results\n",
        "print(y_test-y_predict)"
      ],
      "metadata": {
        "id": "_uNz3VeP2ppC",
        "outputId": "4a9fa439-cf3f-4d8e-f3bb-989959ca9186",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.22413793]\n",
            " [-2.25215517]\n",
            " [ 2.29525862]\n",
            " [ 0.4137931 ]\n",
            " [-2.68103448]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFIWmbCRPuZk"
      },
      "source": [
        "## Finding skill of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzBsGdEiPuZk"
      },
      "outputs": [],
      "source": [
        "# print the R^2 value (coefficient of determination) if R^2 value is greater than 0.75, we accept the model\n",
        "print(model.score(X,Y))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.score(x_test,y_test))"
      ],
      "metadata": {
        "id": "STJy82saqeol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkSM62B7PuZl"
      },
      "source": [
        "## 5. plotting the fitted line using test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmhbhhEsPuZm"
      },
      "outputs": [],
      "source": [
        "plt.title(\"Piza price plotted against diameter\")\n",
        "x_fit=np.linspace(0,50)\n",
        "y_fit=theta_0+theta_1*x_fit\n",
        "plt.axis([0, 25, 0, 25])\n",
        "plt.plot(x_test,y_test,'k.')\n",
        "plt.plot(x_fit,y_fit,color=\"blue\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mSpO7dMPuZm"
      },
      "source": [
        "## 6. Visualizing error in prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAUST2UZPuZm"
      },
      "outputs": [],
      "source": [
        "plt.title(\"Residual line plots\")\n",
        "plt.axis([0, 25, 0, 25])\n",
        "plt.plot(x_test,y_test,'k.')\n",
        "plt.plot(x_fit,y_fit,color=\"blue\")\n",
        "for i in range(0,len(x_test)):\n",
        "    plt.plot([x_test[i], x_test[i]], [yp_test[i], y_test[i]], color='red', linewidth=1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA4r0sogPuZn"
      },
      "source": [
        "## Polynomial regression using scikit learn\n",
        "\n",
        "A linear regression will always have first degree parameters. Example $y=\\theta_0+\\theta_1x$ (simple linear regression). Now there are polynomial regression also: $y_p=\\theta_0+\\theta_1 x^2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTxn0dPTPuZn"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "polyftquadra=PolynomialFeatures(degree=2)\n",
        "Xq_train=polyftquadra.fit_transform(X) # X is the training data\n",
        "Xq_test=polyftquadra.fit_transform(x_test)#transforming input to quadratic way\n",
        "print(Xq_train)\n",
        "print(Xq_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mm0O2gs9PuZo"
      },
      "outputs": [],
      "source": [
        "# train the model\n",
        "\n",
        "modelQ=LinearRegression()\n",
        "modelQ.fit(Xq_train,Y)\n",
        "modelQ.predict(Xq_test)\n",
        "prval=[i[0] for i in modelQ.predict(Xq_test)]#copy values as a list\n",
        "R=modelQ.score(Xq_test,y_test)\n",
        "print(R)\n",
        "plt.plot(x_test,y_test,'k.')\n",
        "plt.plot(x_test,modelQ.predict(Xq_test))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vq8e8QIiPuZo"
      },
      "outputs": [],
      "source": [
        "# Generate a cubic model\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "polyftcubic=PolynomialFeatures(degree=3)\n",
        "Xc_train=polyftcubic.fit_transform(X)\n",
        "Xc_test=polyftcubic.fit_transform(x_test)#transforming input to quadratic way\n",
        "modelC=LinearRegression()\n",
        "modelC.fit(Xc_train,Y)\n",
        "#prvc=[i[0] for i in modelC.predict(Xc_test)]\n",
        "plt.plot(x_test,modelC.predict(Xc_test))\n",
        "modelC.score(Xc_test,y_test) # here R^2 value is less than 0.75, the model is not acceptable."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data from the `.csv` file"
      ],
      "metadata": {
        "id": "_dfUPXN5w79W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gai8EjSnPuZo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# open csv file with pandas\n",
        "df=pd.read_csv(\"/content/Linear_regression.csv\")"
      ],
      "metadata": {
        "id": "NhK7AcgqxIxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "XTl2aBvJxfUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connecting to a `github` repository data"
      ],
      "metadata": {
        "id": "HI6sNwOcyK5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.read_csv(\"https://raw.githubusercontent.com/sijuswamy/PyWorks/main/Linear_regression.csv\")"
      ],
      "metadata": {
        "id": "Yp962ZlHyP-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "HMq4slhhyXZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df1.iloc[:,0].values# create input data\n",
        "Y=df1.iloc[:,1].values# create output data"
      ],
      "metadata": {
        "id": "_yaf8Pq7z3JX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=X.reshape(len(X),1) # reshaping the data\n",
        "Y=Y.reshape(len(Y),1)"
      ],
      "metadata": {
        "id": "3MqT81510HMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e9ZLYG7_1ITo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating an instance of the Linear Regression\n",
        "model=LinearRegression()"
      ],
      "metadata": {
        "id": "ttMXD7RO0T4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,Y)"
      ],
      "metadata": {
        "id": "JF2pxmzT06FK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.intercept_"
      ],
      "metadata": {
        "id": "UsJw-gxz1Plg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.coef_"
      ],
      "metadata": {
        "id": "10aDjgvt1Yaf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}